{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 Linear Model Selections and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ordinary Least Squares Linear Regression modelis great in theory, and even in many applications, however, with the growing amounts of data available, and particularly in high-dimensional datasets, OLS quickly becomes impractical. There is still much value in linear models and this chapter discusses methods of extending the linear model's reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Subset Selection**: identify a subset of predictors, and build model from that subset\n",
    "    * Best subset selection\n",
    "    * Forward stepwise selection\n",
    "    * Backward stepwise selection\n",
    "* **Shrinkage **: fit a model with all predictors, but reduce variance of coefficients by shrinking (regularizing) the coefficients towards zero \n",
    "    * Ridge Regression\n",
    "    * Lasso Regression\n",
    "* **Dimension Reduction**: project $p$ predictors into $M$ dimensions, where $M<p$, by computing $M$ different linear combinations of the variables.\n",
    "    * Principal Component Analysis\n",
    "    * Partial Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Analytics Vidhya Ridge Regression Tutorial](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "#from sklearn.linear_model import Ridge, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitters = pd.read_csv('Data/Hitters.csv', index_col=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Alan Ashby</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alvin Davis</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andre Dawson</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andres Galarraga</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alfredo Griffin</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  \\\n",
       "-Alan Ashby          315    81      7    24   38     39     14    3449    835   \n",
       "-Alvin Davis         479   130     18    66   72     76      3    1624    457   \n",
       "-Andre Dawson        496   141     20    65   78     37     11    5628   1575   \n",
       "-Andres Galarraga    321    87     10    39   42     30      2     396    101   \n",
       "-Alfredo Griffin     594   169      4    74   51     35     11    4408   1133   \n",
       "\n",
       "                   CHmRun  CRuns  CRBI  CWalks League Division  PutOuts  \\\n",
       "-Alan Ashby            69    321   414     375      N        W      632   \n",
       "-Alvin Davis           63    224   266     263      A        W      880   \n",
       "-Andre Dawson         225    828   838     354      N        E      200   \n",
       "-Andres Galarraga      12     48    46      33      N        E      805   \n",
       "-Alfredo Griffin       19    501   336     194      A        W      282   \n",
       "\n",
       "                   Assists  Errors  Salary NewLeague  \n",
       "-Alan Ashby             43      10   475.0         N  \n",
       "-Alvin Davis            82      14   480.0         A  \n",
       "-Andre Dawson           11       3   500.0         N  \n",
       "-Andres Galarraga       40       4    91.5         N  \n",
       "-Alfredo Griffin       421      25   750.0         A  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 263 entries, -Alan Ashby to -Willie Wilson\n",
      "Data columns (total 6 columns):\n",
      "League_A       263 non-null uint8\n",
      "League_N       263 non-null uint8\n",
      "Division_E     263 non-null uint8\n",
      "Division_W     263 non-null uint8\n",
      "NewLeague_A    263 non-null uint8\n",
      "NewLeague_N    263 non-null uint8\n",
      "dtypes: uint8(6)\n",
      "memory usage: 3.6+ KB\n",
      "                   League_A  League_N  Division_E  Division_W  NewLeague_A  \\\n",
      "-Alan Ashby               0         1           0           1            0   \n",
      "-Alvin Davis              1         0           0           1            1   \n",
      "-Andre Dawson             0         1           1           0            0   \n",
      "-Andres Galarraga         0         1           1           0            0   \n",
      "-Alfredo Griffin          1         0           0           1            1   \n",
      "\n",
      "                   NewLeague_N  \n",
      "-Alan Ashby                  1  \n",
      "-Alvin Davis                 0  \n",
      "-Andre Dawson                1  \n",
      "-Andres Galarraga            1  \n",
      "-Alfredo Griffin             0  \n"
     ]
    }
   ],
   "source": [
    "dummies = pd.get_dummies(hitters[['League', 'Division', 'NewLeague']])\n",
    "dummies.info()\n",
    "print(dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hitters.Salary\n",
    "# Drop the column with the independent variable (Salary), and columns for which we created dummy variables\n",
    "X_ = hitters.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "# Define the feature set X.\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Alan Ashby</th>\n",
       "      <td>315.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alvin Davis</th>\n",
       "      <td>479.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andre Dawson</th>\n",
       "      <td>496.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andres Galarraga</th>\n",
       "      <td>321.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alfredo Griffin</th>\n",
       "      <td>594.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4408.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat  \\\n",
       "-Alan Ashby        315.0   81.0    7.0  24.0  38.0   39.0   14.0  3449.0   \n",
       "-Alvin Davis       479.0  130.0   18.0  66.0  72.0   76.0    3.0  1624.0   \n",
       "-Andre Dawson      496.0  141.0   20.0  65.0  78.0   37.0   11.0  5628.0   \n",
       "-Andres Galarraga  321.0   87.0   10.0  39.0  42.0   30.0    2.0   396.0   \n",
       "-Alfredo Griffin   594.0  169.0    4.0  74.0  51.0   35.0   11.0  4408.0   \n",
       "\n",
       "                    CHits  CHmRun  CRuns   CRBI  CWalks  PutOuts  Assists  \\\n",
       "-Alan Ashby         835.0    69.0  321.0  414.0   375.0    632.0     43.0   \n",
       "-Alvin Davis        457.0    63.0  224.0  266.0   263.0    880.0     82.0   \n",
       "-Andre Dawson      1575.0   225.0  828.0  838.0   354.0    200.0     11.0   \n",
       "-Andres Galarraga   101.0    12.0   48.0   46.0    33.0    805.0     40.0   \n",
       "-Alfredo Griffin   1133.0    19.0  501.0  336.0   194.0    282.0    421.0   \n",
       "\n",
       "                   Errors  League_N  Division_W  NewLeague_N  \n",
       "-Alan Ashby          10.0         1           1            1  \n",
       "-Alvin Davis         14.0         0           1            0  \n",
       "-Andre Dawson         3.0         1           0            1  \n",
       "-Andres Galarraga     4.0         1           0            1  \n",
       "-Alfredo Griffin     25.0         0           1            0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-Alan Ashby          475.0\n",
       "-Alvin Davis         480.0\n",
       "-Andre Dawson        500.0\n",
       "-Andres Galarraga     91.5\n",
       "-Alfredo Griffin     750.0\n",
       "Name: Salary, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will fit our Ridge Regression model with 100 different alpha values (it is a bit confusing that in the ISLR book and in R's glmnet() function, they use the variable lambda, but in Scikit-Learn, they use alpha), then determine which corresponds to the most accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize our Variables\n",
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "\n",
    "alphas = 10**np.linspace(10,-2,100)\n",
    "ridge = skl_lm.Ridge()\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha=a)\n",
    "    ridge.fit(scaler.transform(X), y)\n",
    "    coefs.append(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "def Ridge_Regression(X, y, alpha):\n",
    "    scaler = StandardScaler()\n",
    "    ridge = skl_lm.Ridge()\n",
    "    ridge.set_params(alpha=alpha)\n",
    "    ridge.fit(scaler.fit_transform(X), y)\n",
    "    return ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16.43830169,  24.15448953,  11.54113148,  20.8012455 ,\n",
       "        20.00036698,  23.89155483,  13.47868147,  22.48567718,\n",
       "        25.855997  ,  23.99588393,  26.46025971,  26.82575006,\n",
       "        18.86346091,  24.65950143,   1.67820571,  -2.60496312,\n",
       "         4.29756313, -19.60756959,   3.19229238])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_Regression(X, y, alpha=705)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RidgeCV to choose the optimal $\\lambda$ parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([  1.00000e+10,   7.56463e+09, ...,   1.32194e-02,   1.00000e-02]),\n",
       "    cv=None, fit_intercept=True, gcv_mode=None, normalize=False,\n",
       "    scoring='neg_mean_squared_error', store_cv_values=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train = pd.read_csv('Data/Hitters_X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('Data/Hitters_y_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('Data/Hitters_X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('Data/Hitters_y_test.csv', index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "ridgecv = skl_lm.RidgeCV(alphas=alphas, scoring='neg_mean_squared_error')\n",
    "ridgecv.fit(scaler.fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our optimal alpha, ``ridgecv.alpha_=100``, we can plug that into our Ridge Regresssion in order to minimize the Test MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_ridge = skl_lm.Ridge()\n",
    "optimal_ridge.set_params(alpha=ridgecv.alpha_)\n",
    "optimal_ridge.fit(scaler.fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97020.517151355409"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, optimal_ridge.predict(scaler.fit_transform(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat           5.559649\n",
       "Hits           22.893732\n",
       "HmRun          19.431685\n",
       "Runs           19.859330\n",
       "RBI            21.074810\n",
       "Walks          58.870478\n",
       "Years          -6.787442\n",
       "CAtBat         20.752173\n",
       "CHits          30.645308\n",
       "CHmRun         13.816343\n",
       "CRuns          38.037441\n",
       "CRBI           20.334967\n",
       "CWalks         24.582540\n",
       "PutOuts        16.848101\n",
       "Assists       -46.965887\n",
       "Errors         57.761412\n",
       "League_N        6.213095\n",
       "Division_W     -0.816456\n",
       "NewLeague_N    11.254522\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(optimal_ridge.coef_.flatten(), index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's find the optimal alpha using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([  1.00000e+10,   7.56463e+09, ...,   1.32194e-02,   1.00000e-02]),\n",
       "    copy_X=True, cv=None, eps=0.001, fit_intercept=True, max_iter=10000,\n",
       "    n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassocv = skl_lm.LassoCV(alphas = alphas, max_iter=10000)\n",
    "lassocv.fit(scaler.fit_transform(X_train), y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.72267222010321"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101618.27447998914"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = skl_lm.Lasso()\n",
    "lasso.set_params(alpha = lassocv.alpha_)\n",
    "lasso.fit(scaler.fit_transform(X_train), y_train.values.ravel())\n",
    "mean_squared_error(y_test, lasso.predict(scaler.fit_transform(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see by the Test MSE, Ridge Regression performs slightly better than Lasso on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat           -0.000000\n",
       "Hits             0.351477\n",
       "HmRun           17.238693\n",
       "Runs             0.000000\n",
       "RBI             22.438006\n",
       "Walks          104.182138\n",
       "Years          -25.064170\n",
       "CAtBat           0.000000\n",
       "CHits            0.000000\n",
       "CHmRun          -0.000000\n",
       "CRuns          173.024748\n",
       "CRBI             0.000000\n",
       "CWalks          -0.000000\n",
       "PutOuts         21.238595\n",
       "Assists        -69.562708\n",
       "Errors          88.173785\n",
       "League_N         0.928679\n",
       "Division_W       0.000000\n",
       "NewLeague_N      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lasso.coef_.flatten(), index = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, Lasso Regression cancels out many of the predictors, using only 10 of the original 19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3: PCR and PLS Regression (Dimension Reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Components Regression and Partial Least Squares Regression differ from Ordinary Least Squares regression in that instead of making predicting based on a linear combination of predictors, they transform the original predictors $p$ into $M$ predictors where $M<p$, and then use a linear combination of the $M$ predictors to fit a least squares model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expressed mathematically,\n",
    "$$\\sum_{m=1}^{M}\\theta_m z_{im}=\\sum_{m=1}^{M}\\theta_m\\sum_{j=1}^{p}\\phi_{mj}x_{ij}=\\sum_{j=1}^{p}\\sum_{m=1}^{M}\\theta_m\\phi_{mj}x_{ij}=\\sum_{j=1}^{p}\\beta_jx_{ij}, $$\n",
    "where,\n",
    "$$\\beta_j=\\sum_{m=1}^{M}\\theta_m\\phi_{mj}.$$\n",
    "It helps me to think of this as a linear combination of linear combinations. It is important to note that this is still a linear model, and can be thought of as a special case of the original linear regression model. The only difference is that the coefficients are restrained to the form $\\theta_m\\phi_{mj}$.\n",
    "With these restrained coefficients, it is possible to achieve a model with less bias and less variance than the traditional OLS model. It's a win-win!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Components Regression\n",
    "1. Compute the principal component (the normalized linear combination of the variables with the largest variance)\n",
    "2. Compute the second principal component (which has the largest variance subject to being uncorrelated to the first)\n",
    "3. And so on.\n",
    "\n",
    "Hence, with many uncorrelated variables, we replace them with a small set of principal components that capture their joint variation.\n",
    "We identify these principle components by looking solely at our feature matrix $X$, disregarding the target vector $y$. For this reason, these principle components (linear combinations) are identified in an *unsupervised* way. Inherently, PCR assumes that the variables with the largest variance are strong predictors of the target variable. This is often true, but not always the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     187722.760108\n",
      "2     190895.470470\n",
      "3     187952.620187\n",
      "4     191288.431157\n",
      "5     191106.901317\n",
      "6     174100.187213\n",
      "7     172307.316013\n",
      "8     162046.832194\n",
      "9     160028.835931\n",
      "10    173438.191930\n",
      "11    168420.285339\n",
      "12    169267.755551\n",
      "13    168482.151098\n",
      "14    168621.951795\n",
      "15    169485.283815\n",
      "16    162748.143066\n",
      "17    166152.508018\n",
      "18    168582.561441\n",
      "19    169695.115601\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#PCR to predict salary\n",
    "pca = PCA()\n",
    "X_train_reduced = pca.fit_transform(scaler.fit_transform(X_train))\n",
    "regr = skl_lm.LinearRegression()        # We will use OLS to fit our M-dimensional data, derived from PCA\n",
    "\n",
    "# 10-fold CV, with shuffle\n",
    "kf_10 = KFold(n_splits=10, shuffle=False, random_state=1)\n",
    "mse = []\n",
    "\n",
    "for i in np.arange(1, 20):\n",
    "    score = -1*cross_val_score(regr, X_train.values[:,:i], y_train, cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(score)\n",
    "    \n",
    "    \n",
    "mse_per_component = pd.Series(np.array(mse).flatten(), index = np.arange(1,20))\n",
    "print(mse_per_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160028.83593088179"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(mse_per_component)\n",
    "# This lets us know that the model with 9 principal components has the smallest training error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform test data with PCA loadings and fit regression on 6 principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96320.020782503241"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal_pca = PCA(n_components=9)\n",
    "X_test_reduced = pca.transform(scaler.fit_transform(X_test))[:, :7]\n",
    "\n",
    "# train OLS model on PCA-reduced training data\n",
    "pca_regr = skl_lm.LinearRegression()\n",
    "pca_regr.fit(X_train_reduced[:,:7], y_train.values.ravel())\n",
    "\n",
    "# Make predictions with our model and calculate MSE\n",
    "y_pred = pca_regr.predict(X_test_reduced)\n",
    "mean_squared_error(y_test.values.ravel(), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial Least Squares\n",
    "Unlike PCR, PLS identifies its linear combinations is a *supervised* way, making use of the response $y$ in order to identify new features that not only approximate the old features well, but also are related to the response.\n",
    "In practice, PLS generally does not have much of an advantage over PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102234.27995999219"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls = PLSRegression()\n",
    "pls.fit(scaler.fit_transform(X_train), y_train)\n",
    "\n",
    "mean_squared_error(y_test, pls.predict(scaler.fit_transform(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
